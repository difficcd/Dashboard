import urllib.request
import urllib.parse
import json
from collections import defaultdict

# ë„¤ì´ë²„ API í´ë¼ì´ì–¸íŠ¸ IDì™€ ì‹œí¬ë¦¿
client_id = "8OABswwfUim7DZvOemS7"
client_secret = "D8vPrxBOM7"

# ë²•ì•ˆ í‚¤ì›Œë“œ ëª©ë¡, í…ŒìŠ¤íŠ¸ìš©ë„ë¼ 5ê°œë§Œ ì…ë ¥í–ˆìŠµë‹ˆë‹¤ 
law_keywords = ["ë³´ê±´ì˜ë£Œê¸°ë³¸ë²•", "í•­ê³µì•ˆì „ë²•", "ë””ìì¸ë³´í˜¸ë²•", "ì§€ë°©ì„¸íŠ¹ë¡€ì œí•œë²•", "ì „ì„¸ì‚¬ê¸°íŠ¹ë³„ë²•"]

# ë‰´ìŠ¤ ê²€ìƒ‰ì„ ìœ„í•œ ê¸°ë³¸ URL
base_url = "https://openapi.naver.com/v1/search/news.json"

# í—¤ë” ì„¤ì •
headers = {
    "X-Naver-Client-Id": client_id,
    "X-Naver-Client-Secret": client_secret
}

# ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_news(query, start):
    url = f"{base_url}?query={urllib.parse.quote(query)}&display=100&start={start}&sort=date"
    request = urllib.request.Request(url, headers=headers)

    response = urllib.request.urlopen(request)
    rescode = response.getcode()

    if rescode == 200:
        response_body = response.read()
        return json.loads(response_body.decode('utf-8'))
    else:
        print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨: HTTP Error {rescode}")
        return None

# ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í‚¤ì›Œë“œ ë“±ì¥ íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
def count_keywords_in_news(news_items, law_keywords):
    # ë‰´ìŠ¤ ê¸°ì‚¬ ì „ì²´ í…ìŠ¤íŠ¸ ëª¨ìŒ
    all_texts = [
        item["title"] + " " + item["description"]
        for item in news_items
    ]
    
    # í‚¤ì›Œë“œë³„ ë“±ì¥ íšŸìˆ˜ ì„¸ê¸°
    keyword_counts = defaultdict(int)
    for text in all_texts:
        text_lower = text.lower()  # ì†Œë¬¸ìë¡œ ë³€ê²½í•˜ì—¬ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì•°
        for kw in law_keywords:
            if kw.lower() in text_lower:  # í‚¤ì›Œë“œê°€ í…ìŠ¤íŠ¸ì— ì¡´ì¬í•˜ë©´
                keyword_counts[kw] += text_lower.count(kw.lower())  # ë“±ì¥ íšŸìˆ˜ ì¹´ìš´íŠ¸

    return keyword_counts

# ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê¸°ë°˜ í™”ì œ ë²•ì•ˆ TOP 5 ì¶œë ¥ í•¨ìˆ˜
def display_top_keywords(keyword_counts):
    # ì •ë ¬: ë“±ì¥ íšŸìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
    sorted_counts = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)

    # ì¶œë ¥: ê²°ê³¼ê°€ ì œëŒ€ë¡œ ì¶œë ¥ë˜ë„ë¡
    print("ğŸ“Š ìµœê·¼ ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ í™”ì œ ë²•ì•ˆ TOP 5")
    if sorted_counts:
        for i, (kw, count) in enumerate(sorted_counts[:5], 1):
            print(f"{i}. {kw} - ì–¸ê¸‰ {count}íšŒ")
    else:
        print("âš ï¸ ë²•ì•ˆ í‚¤ì›Œë“œê°€ ë‰´ìŠ¤ì— ë“±ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ì£¼ìš” ì‹¤í–‰ íë¦„
def main():
    # 5í˜ì´ì§€ì”© ê°€ì ¸ì™€ì„œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
    total_keyword_counts = defaultdict(int)
    for start in range(1, 501, 100):  # 1, 101, 201, 301, 401ë¡œ 5ë²ˆ ìš”ì²­, ê¸°ë³¸ 100ê°œì”© ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ”ê±¸ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì„œ 5ë²ˆ ìš”ì²­í•´ì„œ 500ê°œ ë‰´ìŠ¤ ê°€ì ¸ì˜´ 
        print(f"ğŸ“¡ {start}ë²ˆì§¸ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        result = get_news("ë²•ë¥ ì•ˆ", start) # 'ë²•ë¥ ì•ˆ' í‚¤ì›Œë“œê°€ ìˆëŠ” ìµœê·¼ ë‰´ìŠ¤ 500ê°œ ì¤‘ì—ì„œ ê²€ìƒ‰ (ì½”ë“œ ìˆ˜ì •í•˜ì—¬ ê°€ì ¸ì˜¤ëŠ” ë‰´ìŠ¤ê¸°ì‚¬ ê°œìˆ˜ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)

        if result and "items" in result:
            news_items = result["items"]
            keyword_counts = count_keywords_in_news(news_items, law_keywords)
            # ê° í˜ì´ì§€ì—ì„œ ë‚˜ì˜¨ í‚¤ì›Œë“œ ë“±ì¥ íšŸìˆ˜ í•©ì‚°
            for kw, count in keyword_counts.items():
                total_keyword_counts[kw] += count

    # ì‹¤ì‹œê°„ í™”ì œ ë²•ì•ˆ TOP 5 ì¶œë ¥
    display_top_keywords(total_keyword_counts)

# ì‹¤í–‰
if __name__ == "__main__":
    main()
