from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import NoSuchElementException
from transformers import pipeline
import plotly.express as px
import plotly.io as pio
import time
from dbmanage_News import SessionLocal, BillNews, Bill
from dbmanage_NewsReact import (
    NewsSentiment,
    init_sentiment_table,  # í…Œì´ë¸” ìë™ ìƒì„± ë³´ì¥
    insert_sentiment_result,
    is_sentiment_already_analyzed
)



init_sentiment_table()

session = SessionLocal()
classifier = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

SIZE = 10 # 10ê°œì”© ìƒˆë¡œ ê°€ì ¸ì˜´
raw_results = (
    session.query(BillNews.news_url)
    .filter(BillNews.news_url != "(ì—†ìŒ)")
    .order_by(BillNews.comment_count.desc())
    .all()
)

# ì¤‘ë³µ ì œê±° (ì•ì—ì„œë¶€í„° ìˆœì„œ ìœ ì§€)
seen = set()
urls = []
for row in raw_results:
    url = row.news_url.strip()
    if url not in seen:
        seen.add(url)
        urls.append(url)
    if len(urls) == SIZE:
        break

comment_urls = [url.replace("/article/", "/article/comment/") for url in urls]
session.close()



def get_comment_url(article_url):
    return article_url.replace("/article/", "/article/comment/")

def load_comments(driver, comment_url):
    driver.get(comment_url)
    time.sleep(5) # ëŒ“ê¸€ë€ ë¡œë”© ëŒ€ê¸° (ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ì¡°ì •)
    

    # ë”ë³´ê¸° ë°˜ë³µ
    for _ in range(30):
        try:
            more_btn = driver.find_element(By.CLASS_NAME, "u_cbox_btn_more")
            if more_btn.is_displayed():
                driver.execute_script("arguments[0].scrollIntoView(true);", more_btn)
                time.sleep(0.5)
                more_btn.click()
                time.sleep(1.5)
        except:
            break

    all_comments = []
    comment_boxes = driver.find_elements(By.CSS_SELECTOR, "li.u_cbox_comment")

    for box in comment_boxes:
        try:
            nickname = box.find_element(By.CLASS_NAME, "u_cbox_nick").text.strip()
            date = box.find_element(By.CLASS_NAME, "u_cbox_date").text.strip()
            text = box.find_element(By.CLASS_NAME, "u_cbox_contents").text.strip()
            like = int(box.find_element(By.CLASS_NAME, "u_cbox_cnt_recomm").text.strip() or 0)
            dislike = int(box.find_element(By.CLASS_NAME, "u_cbox_cnt_unrecomm").text.strip() or 0)

            all_comments.append({
                "ì‘ì„±ì": nickname,
                "ì‘ì„±ì¼ì": date,
                "ëŒ“ê¸€": text,
                "ê³µê°ìˆ˜": like,
                "ë¹„ê³µê°ìˆ˜": dislike,
                "ìœ í˜•": "ë¶€ëª¨"
            })

            # ë‹µê¸€ ì—´ê¸°
            try:
                reply_btn = box.find_element(By.CSS_SELECTOR, "a.u_cbox_reply_btn")
                if reply_btn.is_displayed():
                    driver.execute_script("arguments[0].scrollIntoView(true);", reply_btn)
                    time.sleep(0.3)
                    reply_btn.click()
                    time.sleep(1.0)
            except NoSuchElementException:
                pass

            # ë‹µê¸€ ìˆ˜ì§‘
            reply_boxes = box.find_elements(By.CSS_SELECTOR, "ul.u_cbox_reply li.u_cbox_comment")
            for r_box in reply_boxes:
                try:
                    r_nickname = r_box.find_element(By.CLASS_NAME, "u_cbox_nick").text.strip()
                    r_date = r_box.find_element(By.CLASS_NAME, "u_cbox_date").text.strip()
                    r_text = r_box.find_element(By.CLASS_NAME, "u_cbox_contents").text.strip()
                    r_like = int(r_box.find_element(By.CLASS_NAME, "u_cbox_cnt_recomm").text.strip() or 0)
                    r_dislike = int(r_box.find_element(By.CLASS_NAME, "u_cbox_cnt_unrecomm").text.strip() or 0)

                    all_comments.append({
                        "ì‘ì„±ì": r_nickname,
                        "ì‘ì„±ì¼ì": r_date,
                        "ëŒ“ê¸€": r_text,
                        "ê³µê°ìˆ˜": r_like,
                        "ë¹„ê³µê°ìˆ˜": r_dislike,
                        "ìœ í˜•": "ë‹µê¸€"
                    })
                except NoSuchElementException:
                    continue
        except NoSuchElementException:
            continue
    return all_comments

def analyze_sentiment(comments):
    texts = [c["ëŒ“ê¸€"] for c in comments]
    classifier = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
    result_counts = {"ê¸ì •ì  ì¸ì‹": 0, "ë¶€ì •ì  ì¸ì‹": 0, "ì¤‘ë¦½": 0}
    label_map = {
        "1 star": "ë¶€ì •ì  ì¸ì‹", "2 stars": "ë¶€ì •ì  ì¸ì‹",
        "3 stars": "ì¤‘ë¦½",
        "4 stars": "ê¸ì •ì  ì¸ì‹", "5 stars": "ê¸ì •ì  ì¸ì‹"
    }

    # ë°°ì¹˜ ì²˜ë¦¬
    results = classifier(texts)
    for result in results:
        sentiment = label_map.get(result["label"], "ì¤‘ë¦½")
        result_counts[sentiment] += 1

    return result_counts



def visualize_sentiment(result_counts, title):
    sizes = list(result_counts.values())
    labels = list(result_counts.keys())
    colors = ["#8fb4eb", "#4E5362", "#b0b1b6"]

    if sum(sizes) == 0:
        print(f"âš ï¸ [{title}] ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    fig = px.pie(
        names=labels,
        values=sizes,
        color=labels,
        color_discrete_sequence=colors,
        title=f"[{title}] ëŒ“ê¸€ ê°ì • ë¶„ì„ ê²°ê³¼"
    )

    fig.update_traces(textinfo="label+percent", hole=0.3)
    fig.update_layout(
    font=dict(family="NanumGothic", size=16, color="black"),
    showlegend=True
    )


    fig.show()  


# ë“œë¼ì´ë²„ ì„¤ì •
options = Options()
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")  # ë´‡ ì°¨ë‹¨ ë°©ì§€
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
driver = webdriver.Chrome(options=options)

session = SessionLocal()

# ë‰´ìŠ¤ URL ì¤‘ ì•„ì§ ë¶„ì„ë˜ì§€ ì•Šì€ bill_id ë§Œ ìˆ˜ì§‘
subquery = session.query(NewsSentiment.bill_id).subquery()

raw_results = (
    session.query(BillNews.news_url)
    .join(Bill, BillNews.bill_id == Bill.id)
    .filter(~BillNews.bill_id.in_(subquery))  # ë¶„ì„ë˜ì§€ ì•Šì€ ë‰´ìŠ¤ë§Œ
    .filter(BillNews.news_url != "(ì—†ìŒ)")
    .order_by(BillNews.comment_count.desc())
    .distinct()
    .all()
)

# ì¤‘ë³µ ì œê±° & ìµœëŒ€ SIZEê°œ ìˆ˜ì§‘
seen = set()
urls = []
for row in raw_results:
    url = row.news_url.strip()
    if url not in seen:
        seen.add(url)
        urls.append(url)
    if len(urls) == SIZE:
        break



for url in urls:
    comment_url = get_comment_url(url)
    print(f"\nğŸ”— ê¸°ì‚¬ URL: {url}")

    # ğŸ” bill_id, title ì¡°íšŒ
    bill_row = (
        session.query(Bill.id, Bill.title)
        .join(BillNews, Bill.id == BillNews.bill_id)
        .filter(BillNews.news_url == url)
        .first()
    )
    
    if not bill_row:
        print("âš ï¸ í•´ë‹¹ ë‰´ìŠ¤ URLì´ DBì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
        continue

    bill_id = bill_row.id
    title = bill_row.title

    # âœ… ì´ë¯¸ ë¶„ì„ëœ ë‰´ìŠ¤ëŠ” ìŠ¤í‚µ
    if is_sentiment_already_analyzed(bill_id, url):
        print(f"â­ï¸ ì´ë¯¸ ë¶„ì„ëœ ë‰´ìŠ¤: {bill_id} - {title}")
        continue

    try:
        comments = load_comments(driver, comment_url)
        print(f"  ğŸ“¥ ìˆ˜ì§‘ëœ ëŒ“ê¸€ ìˆ˜: {len(comments)}")

        sentiment_results = analyze_sentiment(comments)

        # âœ… ë¶„ì„ ê²°ê³¼ DB ì €ì¥
        insert_sentiment_result(bill_id, title, url, sentiment_results)

        # âœ… ì‹œê°í™”
        visualize_sentiment(sentiment_results, title=title)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

session.close()
driver.quit()
