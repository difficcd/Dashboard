import json
import urllib.request
import urllib.parse
import time
import re
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer, util
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from concurrent.futures import ThreadPoolExecutor, as_completed

from dbmanage_News import (
    get_bills_by_year, 
    insert_bill_by_year, 
    init_db, 
    insert_bill_news,
    is_news_exist
    )

best_articles_by_title = {}


API_KEY = "68da180a494a4cc3b8add2071dc95242"
client_id = "CKb4pAJ84D6tVcCvpjka"
client_secret = "5PucVvnteo"
YEARS = list(range(2025, datetime.now().year + 1))  # 2016 ~ ì˜¬í•´
MAX_WORKERS = 8  # ë³‘ë ¬ ìŠ¤ë ˆë“œ ê°œìˆ˜ : 6~8 ì¶”ì²œ

# ì„ë² ë”© ëª¨ë¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
model = SentenceTransformer("all-MiniLM-L6-v2")
embedding_cache = {}

def get_embedding(text: str):
    if text not in embedding_cache:
        embedding_cache[text] = model.encode(text, convert_to_tensor=True)
    return embedding_cache[text]

# Selenium ê¸°ë³¸ ì˜µì…˜ â€“ ìŠ¤ë ˆë“œë§ˆë‹¤ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì”€
base_options = Options()
base_options.add_argument("--headless=new")
base_options.add_argument("--no-sandbox")
base_options.add_argument("--disable-dev-shm-usage")

API_URL = "https://open.assembly.go.kr/portal/openapi/TVBPMBILL11"


def _get_bill_rows_by_age(age: int, p_size: int = 1000):
    """íŠ¹ì • *ëŒ€ìˆ˜*ì˜ ëª¨ë“  ë²•ì•ˆ rowë¥¼ ë°˜í™˜."""
    rows, p_index = [], 1
    while True:
        params = {
            "KEY": API_KEY,
            "Type": "json",
            "AGE": age,
            "pIndex": p_index,
            "pSize": p_size,
        }
        url = f"{API_URL}?{urllib.parse.urlencode(params)}"
        try:
            time.sleep(0.1)  # ë„ˆë¬´ ë¹ ë¥¸ í˜¸ì¶œ ë°©ì§€
            req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
            with urllib.request.urlopen(req, timeout=10) as resp:
                data = json.loads(resp.read())
            items = data.get("TVBPMBILL11", [])
            page_rows = items[1].get("row", []) if len(items) > 1 else []
            if not page_rows:
                break
            rows.extend(page_rows)
            if len(page_rows) < p_size:
                break
            p_index += 1
        except Exception as e:
            print(f"[API ì˜¤ë¥˜] {age}ëŒ€ {p_index}í˜ì´ì§€ â†’ {e}")
            break
    return rows


def get_bill_titles_by_year(year: int):
    """ì£¼ì–´ì§„ *year*(YYYY) ì— ë°œì˜ëœ ëª¨ë“  ë²•ì•ˆëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
    titles = []
    # 20â€§21â€§22ëŒ€ êµ­íšŒ ë²”ì£¼ì— ëª¨ë‘ ì§ˆì˜í•œ ë’¤ ë‚ ì§œë¡œ í•„í„°ë§
    for age in (20, 21, 22):
        for row in _get_bill_rows_by_age(age):
            propose_dt = row.get("PROPOSE_DT", "")  # YYYYMMDD í˜•íƒœ
            if propose_dt.startswith(str(year)):
                title = row.get("BILL_NAME", "").strip()
                if title:
                    titles.append(title)
    # ì¤‘ë³µ ì œê±° (ì›ë³¸ ìˆœì„œ ìœ ì§€)
    return list(dict.fromkeys(titles))



def get_comment_count(news_url: str, driver: webdriver.Chrome) -> int:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ URLì—ì„œ ëŒ“ê¸€ ìˆ˜ë¥¼ ë°˜í™˜."""
    try:
        driver.get(news_url)
        time.sleep(1)
        # "ë”ë³´ê¸°" ë²„íŠ¼ ìë™ í´ë¦­
        while True:
            try:
                more_btn = driver.find_element(By.CLASS_NAME, "u_cbox_btn_more")
                driver.execute_script("arguments[0].click();", more_btn)
                time.sleep(0.4)
            except Exception:
                break
        return len(driver.find_elements(By.CSS_SELECTOR, "span.u_cbox_contents"))
    except Exception as e:
        print(f"   [ëŒ“ê¸€ ì‹¤íŒ¨] {news_url} â†’ {e}")
        return 0


def search_news_unique(title: str, sim_threshold: float = 0.4): 
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ê¸°ëŠ¥ì´ ê´€ë ¨ì„±ì„ ì–´ëŠì •ë„ ë³´ì¥í•˜ë¯€ë¡œ 0.0 ìœ¼ë¡œ ìœ ì‚¬ë„ê¸°ì¤€ ì™„í™”
    # ë°˜ëŒ€ ì˜ë¯¸ì˜ ê¸°ì‚¬ì¼ ê²½ìš°ì—ë§Œ ê±¸ëŸ¬ë‚´ë„ë¡ í•¨ (ê±°ì˜ X)

    cleaned = re.sub(r"ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ.*|ì „ë¶€ê°œì •ë²•ë¥ ì•ˆ.*|ì¼ë¶€ê°œì •.*|ì „ë¶€ê°œì •.*", "", title)
    cleaned = re.sub(r"\(.*?\)", "", cleaned).strip()
    query = urllib.parse.quote(cleaned)
    url = f"https://openapi.naver.com/v1/search/news?query={query}&display=100&start=1&sort=date"
    req = urllib.request.Request(url)
    for k, v in (
        ("X-Naver-Client-Id", client_id),
        ("X-Naver-Client-Secret", client_secret),
        ("User-Agent", "Mozilla/5.0"),
    ):
        req.add_header(k, v)

    try:
        with urllib.request.urlopen(req) as resp:
            data = json.loads(resp.read().decode("utf-8"))
        items = data.get("items", [])
        cut_off = datetime.now() - timedelta(days=800)
        title_emb = get_embedding(title)

        best_article = None
        driver = webdriver.Chrome(options=base_options)

        for item in items:
            raw_title = item["title"].replace("<b>", "").replace("</b>", "")
            link = item["link"]
            pubDate = item["pubDate"]
            try:
                pub_dt = datetime.strptime(pubDate, "%a, %d %b %Y %H:%M:%S %z").replace(tzinfo=None)
                if pub_dt < cut_off:
                    continue
            except Exception:
                continue
            if "n.news.naver.com" not in link:
                continue

            sim = util.cos_sim(title_emb, get_embedding(raw_title)).item()
            if sim < sim_threshold:
                continue

            c_cnt = get_comment_count(link, driver)
            if c_cnt < 5:
                continue

            if (
                best_article is None or
                c_cnt > best_article[2] or
                (c_cnt == best_article[2] and sim > best_article[3])
            ):
                best_article = (raw_title, link, c_cnt, sim)

        driver.quit()
        return best_article
    except Exception as e:
        print(f"[ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜] {title}: {e}")
        return None



# ìŠ¤ë ˆë“œ ì‘ì—… í•¨ìˆ˜
def process_title(index: int, title: str, year: int):
    print(f"\n[{index+1:03}] {title} ë‰´ìŠ¤ íƒìƒ‰ ì‹œì‘:")
    if is_news_exist(title, year):
        print(f"[{index+1:03}] dbì— ì €ì¥ëœ ê¸°ì¡´ ë‰´ìŠ¤ë“¤ ëª©ë¡:")
        return  # ë‰´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ì¬ê²€ìƒ‰ X
    result = search_news_unique(title)
    if result:
        best_title, best_link, c_cnt, sim = result
        best_articles_by_title[title] = result
        print(f"[{index+1:03}] âœ… {best_title} ({c_cnt}ê°œ, ìœ ì‚¬ë„ {sim:.3f})")
        print(f"[{index+1:03}] {title} â†’ ğŸ” ìµœë‹¤ ëŒ“ê¸€ ë‰´ìŠ¤ê¸°ì‚¬ ë§í¬ : {best_link}")
        insert_bill_news(
            bill_title=title,
            year=year,
            news_title=best_title,
            news_url=best_link,
            comment_count=c_cnt,
            similarity=sim,
        )
    else:
        print(f"[{index+1:03}] âŒ ë‰´ìŠ¤ ê¸°ì‚¬ ì—†ìŒ ë˜ëŠ” ì¡°ê±´ ë¶ˆì¶©ì¡±")


if __name__ == "__main__":
    init_db()

    for year in YEARS:
        print(f"\n==================== {year}ë…„ ë²•ì•ˆ ====================")
        # 1ï¸ DB í™•ì¸
        titles = get_bills_by_year(year)
        if titles:
            print(f"[INFO] DBì—ì„œ {year}ë…„ ë²•ì•ˆ {len(titles)}ê°œë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        else:
            print(f"[INFO] DBì— {year}ë…„ ìë£Œê°€ ì—†ì–´ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.")
            titles = get_bill_titles_by_year(year)
            print(f"[INFO] {year}ë…„ ë²•ì•ˆ {len(titles)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ.")
            #  DB ì €ì¥
            saved = skipped = 0
            for t in titles:
                try:
                    insert_bill_by_year(year, t)
                    saved += 1
                except Exception as e:
                    print(f"[DB ì €ì¥ ì‹¤íŒ¨] {t} â†’ {e}")
                    skipped += 1
            print(f"[DB ì €ì¥ ê²°ê³¼] ì‹œë„: {len(titles)}, ì„±ê³µ: {saved}, ìŠ¤í‚µ: {skipped}")

        # 3 ë³‘ë ¬ ë‰´ìŠ¤ ê²€ìƒ‰
        if not titles:
            continue
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [
            executor.submit(process_title, i, t)
            for i, t in enumerate(titles)
            if not is_news_exist(t, year)  # âœ… ì´ë¯¸ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
        ]
            for _ in as_completed(futures):
                pass

        
        for title in titles:
            article = best_articles_by_title.get(title)
            if article:
                _, url, _, sim = article
                driver = webdriver.Chrome(options=base_options)
                try:
                    c_cnt = get_comment_count(url, driver)
                    if c_cnt >= 5:
                        print(f"\n   âœ… {article[0]} ({c_cnt}ê°œ, ìœ ì‚¬ë„ {sim:.3f})")
                        print(f"{title} â†’ ğŸ” ìµœë‹¤ ëŒ“ê¸€ ë‰´ìŠ¤ê¸°ì‚¬ ë§í¬ : {url} ")
                finally:
                    driver.quit()


        # ì•½ê°„ì˜ íœ´ì‹ â€“ API ë° ë„¤ì´ë²„ ê³¼ë¶€í•˜ ë°©ì§€
        time.sleep(2)



# -*- coding: utf-8 -*-
"""
 **ë³‘ë ¬ ì²˜ë¦¬** : `concurrent.futures.ThreadPoolExecutor` ë¡œ ë‰´ìŠ¤â€§ëŒ“ê¸€ íƒìƒ‰ì„
   ë³‘ë ¬í™”í•©ë‹ˆë‹¤. ê° ìŠ¤ë ˆë“œëŠ” ìì²´ Chrome WebDriver ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´
   *selenium* ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
 **DB í•¨ìˆ˜ ë„¤ì´ë°** : ``get_bills_by_year`` / ``insert_bill_by_year`` ë¡œ ë³€ê²½.
   (ê¸°ì¡´ ``dbmanage_News`` ëª¨ë“ˆì—ë„ ë™ì¼ í•¨ìˆ˜ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)
 **search_news_unique()** ì™€ ``get_comment_count()`` ê°€ WebDriverë¥¼ ì¸ìë¡œ
   ë°›ì•„ ìŠ¤ë ˆë“œ ê°„ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

ì£¼ì˜
----
* ë²•ì•ˆ APIê°€ **ì—°ë„ íŒŒë¼ë¯¸í„°ë¥¼ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šê¸°** ë•Œë¬¸ì—, ì„¸
  ë²ˆ(20â€§21â€§22ëŒ€) API í˜¸ì¶œ í›„ ``PROPOSE_DT`` ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
* Selenium ë“œë¼ì´ë²„ê°€ ë§ì„ ë•Œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ì´ ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ
  ``MAX_WORKERS`` ê°’ì„ ìƒí™©ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”.
"""
